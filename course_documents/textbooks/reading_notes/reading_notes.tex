\include{./../../latex/notes_style.tex}
%--------------------------------------------------------------------------------------------------------------------------------



\begin{document}
\title{Math 50: Reading notes}

\maketitle

%----------------------------------------------------------------------------------------------------
\section*{Discrete models and simulations (week 1)}
\begin{itemize}
\item  \cite[Section 2.4]{islp}
\item \cite[Section 2.8]{tabak}
\item \cite[Section 2.7]{tabak}
\begin{itemize}
\item  This is where joint and marginal distributions are defined. 
\end{itemize}
\end{itemize}
%----------------------------------------------------------------------------------------------------
\section*{Expectation, Variance, Continuous models and Normal distribution (week 2)}
\begin{itemize}
\item  \cite[Chapter 3]{tabak} 
\begin{itemize}
\item Examples 3.1.6 and 3.17 were covered in class, the other examples are useful to know about, but the calculations are beyond what we do in this course. 
\item I introduced the result of Theorem 3.1.1 as the definition of $E[g(X)]$, but they state it as a Theorem. 
\item Theorem 3.1.2 and Theorem 3.1.3 were covered in class. 
\item Exercise 3.1.2 is very good practice for the exams. 
\end{itemize}
\item  \cite[Section 2.4]{tabak} 
\begin{itemize}
\item I didn't explicitly use their definitions. It might still be useful to skim through and get a different perspective, but don't worry too much about the technical details.
\item Examples 2.4.3 and 2.4.4 were covered in class. 
\item The Normal distribution is introduced on pages 56-59
\item Exercises 2.4.1 and 2.4.2 are good practice.
\end{itemize}
\end{itemize}
%---------------------------------------------------------------------------------------------------
\section*{Central limit theorem, multivariate Normal models, and regression basics (week 3)}
\begin{itemize}
\item \cite[Section 3.3]{tabak}
\begin{itemize}
\item Here is where they cover covariance. 
\end{itemize}
\item \cite[Section 4.4.1]{tabak}
\begin{itemize}
\item Theorem 4.4.3 is the CLT, although stated slightly differently than I stated it. 
\item Exercises 4.4.12-4.4.14 are good practice. 
\end{itemize}
\item \cite[Section 2.5.4]{tabak}  
\begin{itemize}
\item The mixture distributions they discuss are another way to see the conditional models we look at in class. 
\end{itemize}
\item \cite[Section 10.1]{tabak}  
\begin{itemize}
\item Example 10.1.1. This is where they introduce the linear regression model
\end{itemize}
\item \cite[Section 10.3]{tabak}  
\begin{itemize}
\item Theorem 10.3.1 gives the formulas for $a$ and $b$ derived in class. 
\item Theorem 10.3.4 will be discussed in class, time permitted. 
\item The other results are mostly beyond the scope of this course or will be derived later in Week 5. 
\end{itemize}
\item  \cite[Section 3.1.1]{islp}
\begin{itemize}
\item Their presentation of linear regression is quite different than mine. In particular, I take a much more probabilistic approach where the regression model is defined in terms of conditional probabilities. 
\item Formulas 3.4 are the formulas for $\beta_1$ and $\beta_0$ from class (equivalent of \cite[Theorem 10.3.1]{tabak}).
\end{itemize}
\end{itemize}
%---------------------------------------------------------------------------------------------------
\section*{Statistical inference and hypothesis testing (week 4)}
\begin{itemize}
\item \cite[Section 5.1]{tabak}
\begin{itemize}
\item This provides a nice conceptual introduction to statistical inference. 
\item Read Example 5.1.1
\end{itemize} 
\item \cite[Section 5.3]{tabak}
\begin{itemize}
\item Read Example 5.3.4
\end{itemize}
\item \cite[Section 4.4.2]{tabak}
\item \cite[Section 6.3.1]{tabak}
\begin{itemize}
\item Bias and consistency are defined here. 
\item Section 6.1 and 6.2 are also useful, but they go into much more technical detail than we do. 
\end{itemize}
\item \cite[Section 6.3.1]{tabak}
\begin{itemize}
\item Example 6.3.7 is a nice supplement to class
\end{itemize}
\item \cite[Section 3.1.2]{islp}
\begin{itemize}
\item This is a discussion of statistical inference for the regression model. The themes are the same as my lecture notes, but again, I take a much more probabilistic perspective. 
\end{itemize}
\end{itemize}
%---------------------------------------------------------------------------------------------------
\section*{Regression with multiple predictors (week 5-6)}
\begin{itemize}
\item  \cite[Section 10.1]{islp}
\begin{itemize}
\item Example 10.1.2. This is the linear regression model with multiple predictors. 
\item This entire section is useful and all the exercises are good practice. 
\end{itemize}
\item \cite[Section 10.2]{tabak}
\item \cite[Section 10.5]{tabak}
\item \cite[Section 3.2]{islp}
\end{itemize}
%---------------------------------------------------------------------------------------------------
\section*{Interactions, nonlinear models and overfitting (week 7-8)}
\begin{itemize}
\item A great discussion of overfitting and bias variance tradeoff \cite{mehta2019high}
\item Cross validation. I don't really discuss all the difference types of cross validation  \cite[Section 5.1]{islp}
\item Interactions terms are discussed here  \cite[Section 3.3]{islp}
\item Discussion of nonlinear models, although with a different emphasis  \cite[Chapter 7]{islp}
\end{itemize}

%---------------------------------------------------------------------------------------------------
\section*{Prediction and model evaluation (extra)}
\begin{itemize}
\item  \cite[Section 10.5]{tabak}
\end{itemize}
%---------------------------------------------------------------------------------------------------
\section*{Logistic regression (extra)}
\begin{itemize}
\item  \cite[Section 10.5]{tabak}
\item  \cite[Section 4.3]{islp}
\end{itemize}
\


 \bibliographystyle{unsrt}
\bibliography{./../../refs.bib}

 
\end{document}





