\include{./../latex/notes_style.tex}
%--------------------------------------------------------------------------------------------------------------------------------

\title{Exercise set 3}





\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  EXERCISES  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Exercises}



 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Testing for normality]
Here we consider the dataset that can be loaded with 
 \begin{Verbatim}
df = pd.read_csv("https://raw.githubusercontent.com
/avehtari/ROS-Examples/master/Earnings/data/earnings.csv")
\end{Verbatim}

\begin{enumerate}[label=(\alph*)]
\item Let $Y$ denote the data from the column earn, which contains peoples earnings from this sample of adults in the US. Using this sample, estimate
\begin{equation*}
P(Y>\mu_y + 3\sigma_y)
\end{equation*}
where $\mu_y = E[Y]$ and $\sigma_y = \sqrt{{\rm var}(Y)}$ are the mean and standard deviation of the earnings (these will need to be estimated along the way). 
\item Based on your results from part (a), do you think the distribution of earnings is accurately captured by a Normal random variable? 
\item Repeat (a) and (b) with data from the height column. Do you think the variation height data is accurately approximated by a Normal distribution? 
\end{enumerate}
\end{exercise}


% % ------------------------------------------------------------------------------------------------------------------------------------------
%\begin{exercise}[Exploring the CLT] 
%Let 
%\begin{equation*}
%M \sim {\rm Binomial}(N,q).
%\end{equation*} 
%\begin{enumerate}[label=(\alph*)]
%\item What is the CLT approximation to $M$? 
%\item Let $Y$ denote the CLT approximation to $M$ that you found in the previous problem. Let $q=0.5$. For each for $N= 8,10,12,100$ make a plot showing $P(M<k)$ vs. $k$ and $P(Y<k)$ vs. $k$ on the same graph. What is happening as $N$ is getting large? In order to compute $P(M<k)$ and $P(Y<k)$, rather than entering in the probability distribution (which have been giving in class), you can use builtin Python function to compute these. You will need an addition package, which is obtain via
%\begin{Verbatim}
%import scipy.stats as sps
%\end{Verbatim}
%Then, to compute the cumulative distribution function for Normal and binomial random variables you can use 
%\begin{Verbatim}
%sps.norm.cdf(x,mean,var) # P(Z<x) for Z ~ Normal(mean,var)
%sps.binom.cdf(k,N,q) # P(M<k) for M ~ Binomial(N,q)
%\end{Verbatim}
%\item Define the relative error in the CLT approximation when estimating the chance that less than half of the Bernoulli trials are successes; that is, 
%\begin{equation*}
%\epsilon(N/2) = \frac{|P(M<N/2) - P(Y<N/2)|}{P(M<N/2)}
%\end{equation*}
%In other words, $\epsilon(N/2)$ is the difference between the Normal estimate and true probability measured relative to the true probability. 
%Note that this should be very small when the CLT gives a ``good'' approximation.  For each value of  $N= 8,10,12,100$ make a  plot of $\epsilon(N/2)$ as a function of $q$ for $100$ evenly spaced values of $q$ between $0$ and $1$. 
%\item Based on the plots in the previous problem, for what values of $q$ is the CLT approximation work very well, and which values does it not work very well for. How does the accuracy of the approximation depend on $N$? 
%\end{enumerate}
%\end{exercise}


 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Computation with normal variables] 
Let 
\begin{align*}
Z_1 &\sim {\rm Normal}(0,1^2)\\
Z_1 &\sim {\rm Normal}(1,4)
\end{align*} 
be independent. 
\begin{enumerate}[label=(\alph*)]
\item Using the estimates of Normal probabilities in class, compute the following: 
\begin{itemize}
\item $P(Z_1>2)$
\item $P(Z_1 + Z_2<6)$
\item $P(Z_1 - Z_2>4)$
\end{itemize}
\item Check your answers to part (a) with Monte Carlo simulations in python. 
\item ({\bf ungraded -- for additional practice}) Complete following exercises from  \cite{tabak}: 3.3.1, 3.3.2, 3.3.10
\end{enumerate}
%
%Let
%\begin{align*}
%Z_1 &\sim {\rm Normal}(0,1^2)\\
%Z_1 &\sim {\rm Normal}(1,4)
%\end{align*} 
%Compute each of the following using Python
%\begin{enumerate}[label=(\alph*)]
%\item $P(Z_1 + Z_2>3)$
%\item $P(Z_1 + Z_2>3|Z_1<-1)$
%\item $P(Z_2Z_2>0|Z_1+Z_2<4)$
%\item $P(Z_2Z_2>0|Z_1+Z_2<4)$
%%\item Suppose we have a model of hemoglobin levels for men as 
%%\begin{equation*}
%%Z \sim {\rm Normal}(15.8,1.4^2)
%%\end{equation*}
%%(these numbers are in the ballpark but I kinda guessed, so don't try to diagnoise your anemia based on this problem). 
%%Some has Polycythemia if $Z>17.1$. Given that someone has does not have Polycythemia, what is the chance that they are anemic
%\end{enumerate}
\end{exercise}

 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Central limit Theorem]
Suppose 
\begin{equation*}
U_i \sim {\rm Uniform}(u_0-L,u_0+L),\quad i=1,\dots,N
\end{equation*}
Note that, by symmetry, $E[U_i]=u_0$. 
%\begin{equation*}
%S_N = \sum_{i=1}^N U_i
%\end{equation*}
\begin{enumerate}[label=(\alph*)]
\item Using simulations, confirm that \footnote{If you know calculus you should be able to derive this. }
\begin{equation*}
{\rm var}(U_i) = \frac{L^2}{3}.
\end{equation*}
In particular, make a plot of ${\rm var}(U_i)$ as a function of $L$. 
\item Now consider the sum 
\begin{equation*}
S_N = \sum_{i=1}^N U_i
\end{equation*}
Use the CLT to approximate $P(S_N>u_0+L/4)$ in terms of the cumulative distribution of a Normal random variable. 
\item ({\bf optional})  Based on the binomial example in class, how does ratio between the actual probabilities and Normal approximation, that is, 
\begin{equation*}
\text{error} = \left|\frac{P(S_N>u_0+L/4)}{\text{Prob. from Normal approximation}}-1\right|,
\end{equation*}
depend on $L$, $u_0$ and $N$? In particular, you should state whether the error will increase, decrease or stay the same when each of these numbers are increased with the other $2$ fixed. Explain your reasoning.
\item ({\bf optional}) Test your predictions for part $(b)$ with simulations. 
%$How will the answer to this question depend on $L$? 
\item ({\bf optional challenge}). Suppose that $L$ depends on $N$ via $L = h(N)$ where $h(N) \to \infty$ as $N \to \infty$. Therefore, the distribution of $X_i$ depends on $N$ and the CLT no longer applies. Find sequences $a_1,a_2,\dots$ and $b_1,b_2,\dots$ such that 
\begin{equation*}
P\left( \frac{S_N - a_N}{b_N}<z\right) \to P(Z<z)
\end{equation*}
for 
\begin{equation*}
Z \sim {\rm Normal}(0,1).
\end{equation*}
\end{enumerate}

\end{exercise}


 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Model with conditional variance]
Consider the model 
\begin{align*}
X &\sim {\rm Bernoulli}(q)\\
Y|X &\sim {\rm Normal}(a,X + 2(1-X))
\end{align*}

\begin{enumerate}[label=(\alph*)]
\item Is this a linear regression model (for the variable $Y$) as defined in class? Are $X$ and $Y$ independent?
\item Compute ${\rm cov}(X,Y)$. 
\item Confirm your answer by making a plot of the covariance as a function of $q$ from a samples of 10000 $(x,y)$ points. 
\end{enumerate} 
\end{exercise}

 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Swapping response and predictor variables \textcolor{red}{$\star$}]
%Suppose 
%\begin{align*}
%X &\sim {\rm Normal}(\mu_x,\sigma_x^2)\\
%Y &\sim {\rm Normal}(\mu_y,\sigma_y^2)
%\end{align*}
%but that $X$ and $Y$ are not independent, rather ${\rm cov}(X,Y) = C_{x,y}>0$. Show that 
%\begin{equation*}
%{\rm var}(X+Y) = {\rm var}(X) + {\rm var}(Y) + 2
%\end{equation*}
Consider the conditionally normal model introduced in class
\begin{align*}
X &\sim {\rm Normal}(\mu_x,\sigma_x^2)\\
Y|X &\sim {\rm Normal}(\beta_1X + \beta_0,\sigma_{y|x}^2)
\end{align*}
This is a regression model for $Y$. The goal of this problem is to understand the distribution of $X$ conditioned on $Y$. That is, we would like to understand the corresponding regression model for $X$. This is important, because in some applications we have to make a choice about which variable to take as our response and which as our predictor. This exercise will help us understand how the regression parameters we infer depend on this choice. It will also sharpen our understanding of what the covariance really means.  


For some additional motivation, suppose that there is no noise in $Y|X$ (meaning $\sigma_{y|x}^2=0$). Then 
\begin{equation*}
Y =\beta_1X + \beta_0 \implies X = \frac{1}{\beta_1}Y - \frac{\beta_0}{\beta_1}
\end{equation*}
so the slope of $X$ vs.  $Y$ is $1/\beta_1$. We could try adding a normal random variable $Z \sim {\rm Normal}(0,\sigma_{y|x}^2)$ to represent the noise in $Y|X$ and then solve this again. This would lead us to to 
\begin{equation*}
Y =\beta_1X + \beta_0 + Z \implies X=  \frac{1}{\beta_1}Y - \frac{\beta_0}{\beta_1} + \frac{Z}{\beta_1}
\end{equation*}
It is tempting to conclude that $Y|X$ follows a Normal distribution with mean $Y/\beta_1 - \beta_0/\beta_1$ and variance $\sigma_{y|x}^2/\beta_1^2$. This is however false -- see part (c). In this problem you will derive the correct formula. 
 %The problem is that $Z$ and $Y$ are not independent, since $Y|Z$ clearly does not have the same distribution as $Y$. 
%\begin{equation*}
%{\rm Normal}\left( \frac{1}{\beta_1}Y - \frac{\beta_0}{\beta_1} , \frac{\sigma_{y|x}^2}{\beta_1^2} \right)
%\end{equation*}
%Recall that 
%\begin{equation*}
%{\rm cov}(X,Y) = \beta_1 \sigma_x^2, 
%\end{equation*}
%so we might guess that (


\begin{enumerate}[label=(\alph*)]
\item Based on the formula for covariance derived in class, we know 
\begin{equation*}
{\rm cov}(X,Y)  =\beta_1'\sigma_y^2.
\end{equation*}
where $\beta_1'$ is the regression slope on $X$ vs. $Y$ and $\sigma_y^2$ is the marginal variance of $Y$.  
eUsing(1)  ${\rm cov}(X,Y) = {\rm cov}(Y,X)$ (interchanging the role of $X$ and $Y$ doesn't change the covariance) and (2) the marginal variance of $Y$ is $\sigma_y^2 = \beta_1^2\sigma_x^2 + \sigma_{y|x}^2$, derive a formula for $\beta_1'$. 
%\begin{equation*}
%{\rm cov}(X,Y)  =\beta_1'\sigma_y^2.
%\end{equation*}
%where 
%\begin{equation*}
%\beta_1' =\left[\beta_1 + \frac{\sigma_{y|x}^2}{\beta_1 \sigma_x^2}\right]^{-1}. 
%\end{equation*}
\item Using the result of part (a), show that when $\sigma_{y|x}^2 \to 0$ we retrieve the ``naive'' formula $\beta_1' = 1/\beta_1$. 
%\item Now observe that, by applying the formula for $\sigma_y^2$ with the role of $x$ and $y$ reversed, we get
%\begin{equation*}
%\sigma_x^2 = a'\sigma_y^2 + \sigma_{x|y}^2. 
%\end{equation*}
%derive a formula for $\sigma_{x|y}^2$
\item Why is the naive formula $1/\beta_1$ incorrect when $\sigma_{y|x}^2>0$? In particular, why can't we simply solve for $X$ in terms of $Y$ to obtain the regression equation? Hint: does $Y|Z$ have the same distribution as $Y$? 
%\item The result of part (a) means that we can write
%\begin{align*}
%X|Y &\sim {\rm Normal}(\beta_1'Y + \beta_0',\sigma_{x|y}^2)\\
%Y  &\sim {\rm Normal}(\mu_y,\sigma_y^2).
%\end{align*}
%for some $\beta_0'$ and $\sigma_{x|y}^2$. Show that 
% \begin{align*}
%%b' = \mu_x - a'\mu_y. 
%\beta_0' &= \mu_x - \beta_1'\mu_y \\
% \sigma_{x|y}^2 &= (\beta_1')^2 \sigma_y^2  -  \sigma_x^2 
%\end{align*}
%\item The quantity 
%\begin{equation*}
%\rho_{x,y}= \frac{{\rm cov}(X,Y)}{\sigma_x\sigma_y}
%\end{equation*}
%is called the correlation coefficient. Show that 
%\begin{equation*}
%\rho_{x,y} ={\rm sign}(\beta_1)\sqrt{\beta_1'\beta_1}
%\end{equation*}
%where ${\rm sign}(\beta_1) = 1$ if $\beta_1>0$ and $-1$ otherwise. 
\end{enumerate}
\end{exercise}





%
% \begin{exercise}[Election in subdivided population]\label{eq:fail}
% Let's imagine an election in a population subdivided into $L$ groups. The number of people in each group will be denoted $n_i$ and the total number of people in the population is 
% \begin{equation*}
% N = \sum_{i=1}^Ln_i
% \end{equation*}
% We will assume that in the ith group, polling data indicates that the fraction of support for candidate one is $q_i$. 
% \begin{enumerate}[label=(\alph*)]
% \item Assuming that each group is large enough that the CLT can be applied, show that 
% \begin{equation*}
% {\rm var}(\phi) = \frac{1}{N}\sum_{i=1}^L n_iq_i(1-q_i)
% \end{equation*}
% \item Now assume that $n_i = n$ is constant (meaning each county has the same number of voters). Then the expected vote share for candidate $A$ is simply $N\bar{q}$ where $\bar{q}$ is the sample average 
% \begin{equation*}
% \bar{q} = \frac{1}{L}\sum_{i=1}^Lq_i
% \end{equation*}
% Let's now assume $\bar{q} = 1/2$. 
% \end{enumerate}
%
% \end{exercise}





 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[Election model and prediction]
In this exercise you will work with some data on election outcomes and GDP growth. The data can be loaded with 
\begin{Verbatim}
df = pd.read_table("https://raw.githubusercontent.com/avehtari/ROS-Examples/master
/ElectionsEconomy/data/hibbs.dat",sep="\s+");
\end{Verbatim}
The columns are as follows
\begin{itemize}
\item {\bf year:} Year of the election
\item {\bf growth:} A measure of economic growth during the previous four years. 
\item {\bf vote share:} The vote share in percent for the incumbent. 
\end{itemize}
\begin{enumerate}[label=(\alph*)]
\item Fit the data to a linear regression model with economic growth as the predictor and the vote share as the response variable.
%\item Based on the fitted model parameters, how much 
\item Based on your fitted model and neglecting any uncertainty in your estimate, what is your best estimate of the chance that the incumbent will win the election after a period when the economic growth (as measured by the growth variable) is $1$. 
\item What is the chance that after a period of economic growth $=2$ the incumbent will win by a margin of $2\%$. 
%\item Suppose ``true'' values of $\beta_1$ and $\beta_0$ are in-fact $\beta_1 = 0$ and $\beta_1=50$. Then, what is the chance that a random sample of $16$ points from the regression model would yield estimated of value of $a$ greater than $1$? 
\end{enumerate}

\end{exercise}




 % ------------------------------------------------------------------------------------------------------------------------------------------
%\begin{exercise}[Autoregressive model]
%In the autoregressive model, derive the distribution of $X_i|X_{i-2}$. 
%\end{exercise}

 \bibliographystyle{unsrt}
\bibliography{./../refs.bib}

\end{document}




 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}[More on expectation]
Prove each of the following statements and verify with simulations. You can use a probability model from a previous exercise or make up a new one, but you must explain your model and why it satisfied the assumptions of each identity. 
\begin{enumerate}[label=(\alpha*)]
\item Suppose that $X$ and $Y$ are two random variables on (discrete) sample spaces $S_X$ and $S_Y$. 
\begin{equation}
E[X^2]>E[X]^2
\end{equation}
\end{enumerate} 
\end{exercise}
 % ------------------------------------------------------------------------------------------------------------------------------------------
%\begin{exercise}[The CLT theorem vs. large deviations]
%Suppose 
%\begin{equation*}
%S_N \sim {\rm Binomial}(N,p)
%\end{equation*}
%with $N = 100$ and $p=0.1$. 
%Let 
%\begin{equation*}
%F_{n} = P(S_N>n)
%\end{equation*} 


%\end{exercise}



%More formally, how can we understand this in terms of Baye's Theorem? 
%
%That is, what if we FIX the value of $X$. 
%\begin{equation}
%f(y|X = x) = \frac{f(y,x)}{f(x)}
%\end{equation}
%$f(x)$ is the area under the curve 
%This means 

%
%\begin{exercise}
%\href{https://colab.research.google.com/drive/1PPFwE4GUzsr707s3mPhGRs7-TYlHxND2#scrollTo=3CXQuszHxsvn&line=19&uniqifier=1}{Conditioning in the regression model}
%\end{exercise}





 % ------------------------------------------------------------------------------------------------------------------------------------------
\begin{exercise}
The {\bf random walk} is a foundational model in nearly every area of science, from theoretical physics to economics. It describes the "motion" of a variable whose behavior is governed by randomness motion over time. It is defined as follows. 

Let $X_0=0$ and define $X_k$ for $k=1,2,3,\dots$ by the recursive formula 
\begin{align}\label{eq:rw}
X_{k+1} = X_{k}  + \Delta(2U_k - 1)
\end{align}
where $\Delta$ is a constant and 
\begin{equation*}
U_k  \sim {\rm Bernoulli}(1/2)
\end{equation*}
are iid random variables. 


We can think of $X_k$ as the position of a person who is randomly walking with 50-50 chance of the moving to the left or right by $\Delta$ at each time-step. The entire sequence $X_0,X_1,X_2,\dots$ is referred to as the path of the random walker. 
\begin{enumerate}[label=(\alph*)]
\item Write a python function simulaterw(Delta,K) which simulates a random walk for $N$ steps. You code should return the entire path in a numpy array. Make some plots of $X_k$ vs. $k$. 
\item What is $E[X_k|X_{k-1}=2]$ and $E[X_k]$? 
%\item A much harder problem is to calculate $E[X_k|X_{k-1}>0]$. Don't calculate it, but explain why this is more difficult to calculate then the quantities above. 
\item Using the central limit theorem, derive an approximation of the {\bf mean squared displacement}
\begin{equation*}
{\rm MSD}(X_k) = E[X_k^2]
\end{equation*}
(this is just another name for the variance that is used in the context of random walks)
Verify your approximation by plotting ${\rm MSD}(X_k)$ as a function of $N$. 
\end{enumerate}

%You can start by modifying the following function:

\end{exercise}









\end{document}