\include{./../latex/notes_style.tex}
\begin{document}

\title{Statistical inference and hypothesis testing}

\maketitle



%\begin{itemize}
%\item \cite[Section 5.1]{tabak}
%\begin{itemize}
%\item This provides a nice conceptual introduction to statistical inference. 
%\item Read Example 5.1.1
%\end{itemize} 
%\item \cite[Section 5.3]{tabak}
%\begin{itemize}
%\item Read Example 5.3.4
%\end{itemize}
%\item \cite[Section 4.4.2]{tabak}
%\item \cite[Section 6.3.1]{tabak}
%\begin{itemize}
%\item Bias and consistency are defined here. 
%\item Section 6.1 and 6.2 are also useful, but they go into much more technical detail than we do. 
%\item Section 6.3.2 is far beyond the scope of this course, however it is worth a look if you want to go much deeper into confidence intervals and the different types of confidence intervals. 
%\end{itemize}
%\item \cite[Section 6.3.1]{tabak}
%\begin{itemize}
%\item Example 6.3.7 is a nice supplement to class
%\end{itemize}
%\item \cite[Section 3.1.2]{islp}
%\begin{itemize}
%\item This is a discussion of statistical inference for the regression model. The themes are the same as my lecture notes, but again, I take a much more probabilistic perspective. 
%\end{itemize}
%\item \cite[Section 3.6.1 and 3.6.2]{islp}
%\begin{itemize}
%\item I highly recommend working through this example of regression in statsmodels
%\end{itemize}
%\end{itemize}





\section{Estimators}
\begin{itemize}
\item With the concept of a random variable we can now define mathematically what we mean by statistical inference. Let $Y$ be some random variable, e.g. 
\begin{equation*}
Y \sim {\rm Normal}(\mu,\sigma). 
\end{equation*}
{\bf Statistical inference is the process of estimating the parameters (e.g. $\mu$ and $\sigma$) based on samples of $Y$ AND expressing our uncertainty in these estimates.}
\item As we have already pointed out many times, in order to estimate parameter $\theta$, we can use the following facts: 
\begin{enumerate}
\item Both $\mu$ and $\sigma$ can be represented as means over the distribution of $Y$. For example $\theta = E[\theta]$. 
%\begin{equation}
%\mu = \E[Y],\quad \sigma^2 = {\rm var}(Y) = \E\left[(Y-\E[Y])^2\right]
%\end{equation}
\item If we have enough samples the sample average should be close to the actual average.  That is, $1/N\sum_{i=1}^Nf(Y_i) \approx E[f(Y)]$. The central limit theorem tells us how accurate this estimate is. 
%\begin{equation}
%\frac{1}{N}\sum_{i=1}^Nf(Y) \approx \E[f(Y)]. 
%\end{equation} 
\end{enumerate}
In general, we will let $\hat{\theta}$ denote an \dfn{estimator} of a parameter $\theta$ from a sample if $\hat{\theta}$ is some function of our sample which is meant to approximate $\theta$.  For example 
\begin{equation*}\label{eq:muhat}
\hat{\mu} = \frac{1}{N}\sum_{i=1}^N Y_i
\end{equation*}
is an estimator of $\mu$ in the Normal model. It also happens to be the sample mean: $\hat{\mu} = \bar{Y}$. 

\item {\bf $\hat{\theta}$ vs. $\theta$}
{\bf Remember:} the estimator is a function of the data. That is, {\bf $\hat{\theta}$ depends on the specific data we collect} or simulation we run. It is meant to approximation a parameter which $\mu$ does not depend on the data and is (in classical statistics) a fixed number. For example,  in the instance of a YES/NO survey or election with two candidates, the ``true'' quantity we are interested in measuring is the fraction of people answering YES to some question. Our estimate, $\hat{q}$, is a variable which depends on the specific subset of the population we sample. 
\end{itemize}


\subsection{Sample distribution and standard errors}
\begin{itemize}

\item Since $\hat{\theta}$ depends on the data, different replications of our sample will generate different values of $\hat{\theta}$. We can therefore think of $\hat{\theta}$ as a random variable itself.  We call the distribution of $\hat{\theta}$ over many replications of our data the \dfn{sample distribution}. I will use \dfn{replicate} to mean different realizations of our data (as opposed to the different samples within the data). The distinction is shown in Figure \ref{fig:reps_samp} (left panel). The terminology gets a bit confusing: The sample distribution is the distribution of $\hat{\theta}$ over many replicates, but each replicate involves many samples. 

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{./../figures/replicates}
\caption{Replicates and samples }\label{fig:rep_samp}
\end{figure}


\begin{example}[sample distribution of normal mean]
Suppose 
\begin{equation*}
Y \sim {\rm Normal}(\mu,\sigma)
\end{equation*}


\noindent
\underline{Question:} What is the sample distribution of $\hat{\mu}$ (our estimate of $\mu$)?\\

\noindent
\underline{Solution:}
\begin{equation*}
\hat{\mu} = \bar{Y} = \frac{1}{N}\sum_{i=1}^NY_i
\end{equation*}
The CLT tell us (informally speaking) that 
\begin{equation*}
\sum_{i=1}^NY_i \sim {\rm Normal}\left(\mu n,n\sigma^2 \right)
\end{equation*}
where by $\sim$ we really mean ``approximately distributed as''. Dividing by $N$, 
\begin{equation*}
\hat{\mu} \sim {\rm Normal}\left(\mu ,\frac{\sigma^2}{N} \right)
\end{equation*}
This assumes $\sigma$ is known.
%\begin{align*}
%P\left( \bar{Y}<y \right) &= P\left(\frac{\sum_{i=1}^nY_i - n\mu}{\sqrt{n \sigma^2}} < \frac{n - n \mu }{\sqrt{n\sigma^2}}y \right)\\
%&=  P\left(\frac{\sum_{i=1}^nY_i - n\mu}{\sqrt{n \sigma^2}} <\sqrt{n} \frac{1-\mu }{\sqrt{\sigma^2}}y \right)\\
%& \to P(Z<z),\quad Z \sim {\rm Normal}(0,1)
%\end{align*}

%From Equation \ref{eq:muhat}, $\hat{\mu}$ is the sum of independent Normal random variables. We know that this is also Normal and has variance $\sigma^2/N$, hence the sample distribution is 
%\begin{equation}
%\hat{\mu} \sim {\rm Normal}(\mu,\sigma/\sqrt{N}). 
%\end{equation}
\end{example} 

\item A natural way to quantify the uncertainty in our estimate is the standard deviation of the $\hat{\mu}$ under the sample distribution.  We call the resulting quantity the \dfn {standard error}, which is our \dfn{estimate} of the standard deviation of the sample distribution.  For the Normal model, if we are estimating the mean and happen to know $\sigma$, then 
\begin{equation}\label{eq:se1}
{\rm se}(\hat{\mu}) =  \frac{\sigma}{\sqrt{N}}. 
\end{equation}
This tells us how much our estimate will vary between different experiments (or surveys/simulations). 
Importantly, the standard error depends on $\sigma$ which we may not know!!! Thus, it is common to estimate the standard error using an estimate of $\sigma$, $\hat{\sigma}$, leading to an estimator of the standard deviation:
\begin{equation}\label{eq:se2}
{\rm se}(\hat{\mu}) =  \frac{\hat{\sigma}}{\sqrt{N}}. 
\end{equation}
It should be clear from the context which one we are talking about: If we are working with data and we don't know what $\sigma$ is, when we say standard error we mean Equation \ref{eq:se2}. If we are working with a particular model where we have specified the parameters, we mean Equation \ref{eq:se1}. 
\end{itemize}



%\begin{example}
%\href{https://colab.research.google.com/drive/1QarJhwPmSqCTQ-HwU_lXCUX6uvdhLdrM#scrollTo=jmB0Mvksc6B_&line=1&uniqifier=1}{Using standard errors to design an experiment}
%\end{example}



% This should be $Y/N$, since for an individual response $x_i =0,1$, $\E[x_i] = q$ and 
% \begin{equation}
% \bar{x}_i = Y/N \approx \E[x_i] = q. 
% \end{equation}
% At the same time, we expect that for any particular sample of the population 
%\begin{equation}
%\frac{Y}{N} \ne q
%\end{equation}
%since there is always a chance that we happen to sample more or less people who answer YES.  In this case we call $Y/N$ an {\dfn estimator} of $q$, and write $\hat{q}(Y) = Y/N$. 





%In classical statistics, we measure accuracy using the standard error, denoted ${\rm se}(\hat{q})$.  The standard error is the standard deviation of $\hat{q}(Y)$ taken over different samples of our data.  If we are, say, flipping a coin and tallying the result to obtain $Y$, it is clear what this means. If $Y$ is the vote share from a one-off election, then is becomes a bit puzzling to think about replicating the experiment. Fortunately, this is a philosophical problem, not a mathematical one. Mathematically, we can always define ${\rm se}(\hat{q})$ \emph{within the context of our model} as 
%\begin{equation}
%{\rm se}(\hat{\theta}) = \sqrt{{\rm var}(\hat{\theta}(Y))}
%\end{equation}
%where the variance is taken over the distribution of $Y$. That is, we use the probability distribution $P(Y)$ to compute this variance. 
%Roughly speaking, if we performed many experiments and measured $\hat{q}$, the measurements will typically differ by ${\rm se}(\hat{q})$. It is helpful to visualize this. 







%
%For the binomial model, we can calculate ${\rm se}(\hat{q})$ using what we've already learned. 
%Since $\hat{q} = M/N$ we calculate the variance, but we need to know that 
%\begin{equation}
%{\rm var}(aX) = a^2{\rm var}(X) \,\,\, \text{ or } \sqrt{{\rm var}(aX)} = a\sqrt{{\rm var}(X)}
%\end{equation}
%Then it follows that 
%\begin{equation}
%{\rm var}(\hat{q}) = {\rm var}\left(\frac{M}{N}\right)  = \frac{1}{N^2}\times Nq(1-q) = \frac{q(1-q)}{N}
%\end{equation}
%so ${\rm se}(\hat{q}) = \sqrt{q(1-q)/N}$. 
%
%Another way to arrive it this is through the central limit theorem: $\hat{q}$ is approximately Normal with mean $\E[Y_i]$ and standard deviation $\sqrt{q(1-q)/N}$. We can use the Normal approximation to determine how large $N$ should be when we design an experiment. 




\subsection{Bias and consistency}

\begin{itemize}
\item There must be some properties we would like the estimator to have. At a minimum, it should be in some way informed by the data, in the sense that having more data should bring our estimate closer to the actual value of the parameter. More precisely, the more data we have (e.g. the larger $N$) the closer we expect $\hat{\theta}$ to be to the true value $\theta$. Of course, we must define what we mean by "closer" when we are talking about random things. 
For our purposes we will say $\hat{\theta}$ is \dfn{consistent} if 
\begin{equation*}
E[\hat{\theta}] \to \theta\,\,\text{ and } {\rm se}(\hat{\theta})  \to 0 \,\,\,\text{ as }\,\, N\to \infty. 
\end{equation*}
This is saying that as we obtain more and more samples, the sample distribution because more concentrated around $\theta$. 


%\begin{boxB}{Understanding consistency}
%To better understand the notation of consistency, let's consider two rather silly ways to estimate $q$ in a Bernoulli distribution. Let $\hat{q}_1$ and $\hat{q}_2$ be two other estimators of $q$ defined by 
%\begin{align}
%\hat{q}_{0} &= \frac{Y}{N}\\
%\hat{q}_{1} &= \frac{Y}{N} + \frac{1}{N}\\
%\hat{q}_{2} &= \frac{y_1 + y_2}{2}
%\end{align}
%where
%\begin{equation}
%
%\end{equation}
%The sample distribution of $\hat{q}$ is 
%\begin{equation}
%
%\end{equation}
% \href{https://colab.research.google.com/drive/1QarJhwPmSqCTQ-HwU_lXCUX6uvdhLdrM#scrollTo=US27cD1JgXn_&line=3&uniqifier=1}{code}
% \end{boxB}
\item To see that consistency is not the only property we look for in an estimator, notice that since $\hat{\mu}_1 = \hat{\mu} + 1/N$ is also consistent, yet clearly seems inferior to $\hat{\mu}$. To this end, we say that an estimator $\hat{\theta}$ is \dfn{unbiased} for some $N$ (not just very large $N$), the average over the sample distribution is equal to the actual value under the model distribution; that is, 
\begin{equation*}
E[\hat{\theta}] = \theta. 
\end{equation*} 

\begin{example}[Bias and consistency]
For a normal random variable, define the following estimators of the mean:
\begin{align*}
%\hat{\mu}_1 &= \frac{1}{N}\sum_{i=1}^NY_i + \frac{1}{N}\\
\hat{\mu}_2 &= \frac{Y_1 + Y_2}{2}
\end{align*}

\noindent
\underline{Question:}  Is $\hat{\mu}_2$ biased and consistent? what is the sample distribution?\\


\noindent
\underline{Solution:}
%Note that  $\hat{\mu}_1 = \hat{\mu} + 1/N$ so it has the sample distribution  
%\begin{equation*}
%\hat{\mu}_1 \sim {\rm Normal}(\mu+1/N,\sigma/\sqrt{N})
%\end{equation*}
%while 
Note that $\hat{\mu}_2$ has the sample distribution 
\begin{equation*}
\hat{\mu}_2  \sim {\rm Normal}(\mu,\sigma/\sqrt{2})
\end{equation*}
\end{example}


\begin{example}[Normal standard deviation]
Let now consider estimating the standard deviation of a Normal random variable
\begin{equation*}
Y \sim {\rm Normal}(\mu,\sigma^2)
\end{equation*}
Given samples $Y_1,Y_2,\dots,Y_n$, it seems the natural way to estimate $\sigma^2$ is using
\begin{equation*}
{\rm var}(Y) = E[(Y-E[Y])^2] \approx \frac{1}{n}\sum_{i=1}^n(Y_i-\overline{Y})^2
\end{equation*}
we will call this estimator $\hat{\sigma}_0^2$. It turns out $\hat{\sigma}_0^2$ is biased and in-fact 
\begin{equation*}
\hat{\sigma}^2 = \frac{1}{n-1}\sum_{i=1}^n(Y_i-\overline{Y})^2 = \frac{n}{n-1}\hat{\sigma}_0^2
\end{equation*}
is unbiased. The correction by a factor $n/(n-1)$ is called Bessel correction. \\

\noindent
\underline{Question:} Demonstrate with simulated data that $\hat{\sigma}_0^2$ is biased and $\hat{\sigma}^2$ is not. 


\end{example}




\end{itemize}




\subsection{Confidence intervals}

\begin{itemize}

\item The idea of the \dfn{confidence interval} is, roughly speaking, to describe the range of values where we think the actual value of $\theta$ might reasonable be given some estimate $\hat{\theta}$ and its sample distribution. We will mostly work with the $95\%$ \dfn{ confidence interval}, or $95\%$-CI, which is given by 
\begin{equation}\label{eq:95CI}
[\hat{\theta} - 1.96{\rm se}(\hat{\theta}), \hat{\theta} + 1.96{\rm se}(\hat{\theta})]
\end{equation}
The factors $1.96$ in front of the standard errors ensure that $95\%$ of samples from the sample distribution will fall in this range, 



Note that these samples from the sample distribution do not have the same distribution as $\hat{\theta}$ over replicates of our data. Said another way, if we draw many samples from our estimate of the sample distribution, their distribution will not be the same as the distribution of $\hat{\theta}$ we would obtain if we ran an experiment many times and estimated $\hat{\theta}$ each time. The correct interpretation of the $95\%$-CI is as follows: {\bf If we generate many replicates of the data then $\theta$ (the true value) will fall in the CI, for $95\%$ of them.} 

Technically speaking, is is NOT the case that there is a $95\%$ chance the true value of $\theta$ is in the $95\%$-CI. 
To understand why, note that the parameter has a $95\%$ chance to be in the interval 
\begin{equation}\label{eq:95CIB}
[\theta - 1.96{\rm std}(\theta),\theta + 1.96{\rm std}(\theta)]
\end{equation}
but this is difference from Equation \ref{eq:95CI}, since we have replaced $\hat{\theta}$ with $\theta$. The distinction, which is shown in Figure \ref{fig:CI}, is important; however, you don't need to get bogged down by the subtle differences in interpretation. For practical purposes, you can pretty much thing of the $95\%$-CI as the region where the parameter value is likely to be. We provide alternatives ways to think about these intervals when we discuss Bayesian vs. classical statistics. 


\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{./../figures/notes3CI}
\caption{An illustration of the distinction between Equation \ref{eq:95CIB} (gray shaded region) and Equation \ref{eq:95CI}.   }\label{fig:CI}
\end{figure}

\begin{example}[Estimating CI]
% NEED BETTER MOTIVATION
Imagine we are designing an experiment. Our model is a Normal distribution and from previous experience, we have a ballpark estimate of the standard deviation, which is $\sigma \approx 0.1$.  \\



\noindent
\underline{Question:} Roughly, how many samples do we need to collect to have a $95\%$ chance our estimate is within $0.1$ of the actual value of the variable?\\



\noindent
\underline{Solution:} The standard deviation of an estimate based on $n$ samples will have a confidence interval of 
\begin{equation*}
[\hat{\mu}-0.196/\sqrt{n},\hat{\mu} +  0.196/\sqrt{n}]
\end{equation*}
The width of this interval is $2 \times 0.196/\sqrt{n}$. This interval will intersect the true value in $95\%$ of replicates, so we would like it to have a width $<0.2$. It follows that we need 
\begin{equation*}
1.96^2 = 3.8 < n 
\end{equation*}
We can test this by running many replicates for each $n$, as done in the class notebook. 
% Make a plot of the sample fraction of samples with $0.1$ of the actual mean as a function of the number of samples to confirm the result of part (a)
\end{example}
%\item There is an alternative way to think about the CI: as a measure of our belief in the parameter value. This interpretation is more n%atural for me, and we will discuss how to formalize it in the context of Bayesian statistics. 
\end{itemize}



%\begin{exercise}
% \href{https://colab.research.google.com/drive/1QarJhwPmSqCTQ-HwU_lXCUX6uvdhLdrM#scrollTo=US27cD1JgXn_&line=3&uniqifier=1}{Understanding bias}
%\end{exercise} 

%------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Maximum Likelihood}
\begin{itemize}
\item
Sometimes it is quite clear what the estimator for a parameter should be. This is the case for $q$ in the Bernoulli distribution. However, we will find this is not always the case, so it is useful to have a {\bf more systematic way of finding estimators.} 
\item Recall that the probability distribution for the binomial distribution is 
\begin{equation}\label{eq:binomial-pdf}
p(Y) = {n \choose Y}q^Y(1-q)^{n-Y}
\end{equation}
In statistics, we sometimes call this the \dfn{likelihood} and denoted $P(Y) = L(Y|q)$. The notation here is suggesting that we think of $P$ as a distribution which is conditioned on a particular value of the parameter.  More generally, the likelihood is defined as the probability we say a data set given the parameters. This notation and terminology foreshadows Bayesian thinking, wherein one thinks of the parameter as random variables themselves -- more on this later. 
\item For now, notice that Equation \eqref{eq:binomial-pdf} tells us how likely it is to observe $k$ YES among $n$ people surveyed. Then, it seems reasonable that this number should not be very small, since that would mean our survey results are an anomaly. More generally, the larger $L(Y|q)$ is the more likelihood our results are. This suggests one a way to estimate determine $q$: We can take as our estimate $\hat{q}$ the value which makes $L(Y|q)$ largest. In other words, we are finding the value of $q$ which makes the data the most likely, and we will call this the \dfn {maximum likelihood estimate}.
\item You can do this using calculus (if you know how, I suggest you give it a try) to determine that the value of $q$ which makes \eqref{eq:binomial-pdf} largest is \begin{equation*}
\hat{q}_{\rm MLE} = \frac{Y}{n}
\end{equation*}
\item For a Normal distribution with mean and variance $\mu$ and $\sigma$, the MLE estimators are the usual sample mean and standard deviation which we have already been exposed to. 
\end{itemize}
%\begin{equation}
%\hat{\mu}_{\rm MLE} = \frac{1}{n}\sum y_i
%\end{equation}
%and 
%\begin{equation}
%\hat{\sigma}_{\rm MLE} = \sqrt{\frac{1}{n-1}\sum ( y_i - \hat{\mu})^2}
%\end{equation}






%------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Statistical inference for regression model using python}

% NOTE: Maybe move earlier problem about ballpark estimate in test score model here
\begin{itemize}
\item Having introduced the concepts and terminology of statistical inference, we return to the linear regression model with a single predictor:
\begin{align*}
Y|X \sim {\rm Normal}(\beta_0 + \beta_1X,\sigma^2).
\end{align*}
We will sometimes write such a model as
\begin{equation*}
Y = \beta_0 + \beta_1X + \varepsilon
\end{equation*}
where it is assumed that 
\begin{equation*}
\varepsilon \sim {\rm Normal}(0,\sigma^2)
\end{equation*}
Note that this model does not describe the distribution of $Y$, rather it describes the distribution of $Y$ given $X$. What we are really saying is that once we are given a value of $X$, the variation in $Y$ is approximately normal with an $X$ independent variance. The formulas for estimators of $\beta_0$ and $\beta_1$ have already been given. You can look up formulas for the standard errors in the textbook, we will just have Python give us these. 
Note that the sample distributions of $\hat{\beta}_0$ and $\hat{\beta}_1$ are NOT normal, but we will not worry about trying to compute them in this class (at least for now). 
\item In addition, we want to estimate $\sigma^2$. To do so, we can note that 
\begin{equation*}
Y - (\beta_0 +\beta_1X) \sim {\rm Normal}(0,\sigma^2).
\end{equation*}
Therefore, with our estimates  $\hat{\beta}_0$ and $\hat{\beta}_1$, we can compute the residuals of each data point
\begin{equation*}
r_i = Y_i  -  (\hat{\beta}_0 +\hat{\beta}_1X_i).
\end{equation*}
An estimate of $\sigma^2$ is approximately the sample variance of $r_i$. We need to account for the fact that we don't know $\beta_0$ and $\beta_1$ exactly though (just like with Bessels correction), and therefore the unbiased estimator is
\begin{equation*}
\hat{\sigma}^2= \frac{1}{n-2} \sum_{i=1}^nr_i^2. 
\end{equation*}
We will refer to the process of computing the coefficient estimates and standard errors as \dfn{fitting} the model. 


\item   In order to perform statistical inference for a linear regression model in Python, we use the \verb!statsmodels! package. \verb!statsmodels! has a function \verb!OLS! which can take two arguments
\begin{itemize}
\item An array \verb!y! -- the response variables
\item and a matrix \verb!X! -- which contains the predictors. 
\end{itemize}
Technically,  \verb!OLS! will create a regression model of the form 
\begin{equation*}
Y = \beta_0 X_0 + \beta_1 X_1 + \beta_2 X_2 +\cdots + Z
\end{equation*}
where $Z$ is mean zero normal. Notice there is not intercept, instead we have a term $\beta_0 X_0$. We need to trick  \verb!OLS!
into creating a model with a single predictors AND an intercept by creating a new predictor $X_0$ which is always one. This is achieved with the line of code
\begin{Verbatim}
X = sm.add_constant(x)
\end{Verbatim}
where $x$ is jus the array of our $X$ values (playing the role of $X_1$ in the equation above). 
Then 
\begin{Verbatim}
model = sm.OLS(y,X)
\end{Verbatim}
create a model ``object''. At this point we haven't actually performed any inference, rather we have created an data structure, called an object, which has all the information about our model and data. The next step is to tell python to fit this model -- that is, to infer the parameter values -- and store the results. This is done via
\begin{Verbatim}
results = model.fit(). 
\end{Verbatim}
Results contains all the information about the fitted model, including the inferred, or fitted, coefficients, standard errors, as well as many things I will soon discuss. We can print all this out with the line of code 
\begin{Verbatim}
print(results.summary())
\end{Verbatim}
This will produce something like
\begin{Verbatim}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.612
Model:                            OLS   Adj. R-squared:                  0.610
Method:                 Least Squares   F-statistic:                     312.1
Date:                Thu, 05 Oct 2023   Prob (F-statistic):           1.47e-42
Time:                        12:43:13   Log-Likelihood:                -519.05
No. Observations:                 200   AIC:                             1042.
Df Residuals:                     198   BIC:                             1049.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          7.0326      0.458     15.360      0.000       6.130       7.935
x1             0.0475      0.003     17.668      0.000       0.042       0.053
==============================================================================
Omnibus:                        0.531   Durbin-Watson:                   1.935
Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669
Skew:                          -0.089   Prob(JB):                        0.716
Kurtosis:                       2.779   Cond. No.                         338.
==============================================================================
\end{Verbatim}
The value of \verb!const! is the intercept $\beta_0$ and \verb!x1! is the coefficient of $X$ in our regression model -- that is, the slope $\beta_1$. You can access the various quantities directly from the results object via the commands in Table \ref{tab:sm}.

\begin{table}[h]
\centering
\begin{tabular}{lr}
\textbf{quantity} & \textbf{Command}  \\
\hline
\hline
$\beta_i$ &  \verb!results.params! \\
$\hat{\sigma}^2$ &  \verb!results.scale! \\
${\rm se}(\hat{\beta}_i)$  & \verb!results.bse! \\
\end{tabular}
\caption{}
\label{tab:sm}
\end{table}



\begin{example}[Performing linear regression in statsmodels]

Here we once again consider the some on advertising budgets and sales for a company.\\



\noindent
\underline{Question:} Fit the data to a linear regression model using \verb!statsmodels! and compare to the results we got before. \\ 


\end{example}
\end{itemize}

\subsection{Assessing explanatory power with $R^2$}
\begin{itemize}
\item We have so far seen how to estimate and interpret the parameters in the regression model with one predictor). So far, most of the quantities we compute depend heavily on the intrinsic scales of the data. For example, if we are working with height data as our predictor and use units of inches, we will get very different values of $\hat{\beta}_1$ than if we had used feet. The same is true for the other parameters. It is therefore useful to have a summary of the descriptive power of our model in terms of a quantity that does not depend on these scales. %Recall that the covariance is one way to measure. 
\item To find an appropriate metric for accessing the descriptive power of our model, the idea is to compare the variation in $Y$ over all (that is, the marginal variance), to the variation conditioned on $X$. To this end, we define the \dfn{correlation coefficient} by 
\begin{equation}
\rho^2 = 1 - \frac{{\rm var}(Y|X)}{{\rm var}(Y)} = 1 - \frac{\sigma^2}{\beta_1^2\sigma^2 +\sigma_x^2} \approx R^2
\end{equation}
The quantity called $R^2$ is simply the estimator of this with all the quantities above replaced by their sample estimates:
\begin{equation*}
R^2 = 1 - \frac{\sum_{i=1}^nr_i^2}{\sum_{i=1}^n (Y_i - \overline{Y})^2}
\end{equation*}
\item There is a relationship between $\rho$ and the covariance 
\begin{equation*}
\rho = \frac{{\rm cov}(X,Y)}{\sigma_x\sigma_y}. 
\end{equation*}
I'll leave it as an exercise to show this. This provides provides another interpretation of $\rho$ (and hence $R^2$) which comes from one of the earlier exercises. In particular, if $\beta_1$ and $\beta_1'$ are respectively the regression slopes of $Y$ vs. $X$ and $X$ vs. $Y$, we can then write $\rho$ as 
\begin{equation*}
\rho  =  \frac{{\rm cov}(X,Y)}{\sigma_x\sigma_y} =  \frac{{\rm sign}(\beta_1)\sqrt{\beta_1'\beta_1}\sigma_x\sigma_y}{\sigma_x\sigma_y} = {\rm sign}(\beta_1)\sqrt{\beta_1'\beta_1}. 
\end{equation*}


\begin{example}[Performing linear regression in statsmodels]


\noindent
\underline{Question:} Generate simulated data with different values of $R^2$ \\ 

\noindent
\underline{Solution:} See python notebook. \\ 
\end{example}

\end{itemize}



%------------------------------------------------------------------------------------------------------------------------------------------------------
\section{Hypothesis testing}
\begin{itemize}
\item In statistics, we might infer parameters not because we are interested in specific values, but rather because we would like to use them to make a decision. For example, in a clinical trial, we might be interested in deciding whether a candidate drug is worth moving forward with. This problem is often framed in terms of \dfn{hypothesis testing}, in which we assign a probability to a particular hypothesis or its converse. 
\item In rather abstract terms, the basic procedure of hypothesis testing is as follows:
\begin{enumerate}
\item Come up with a \dfn{null hypothesis}. For example, this might be that the mean of some variable is zero. We are interested in determining whether we can rule this hypothesis out. 
\item Compute something called a \dfn{test statistic}, denoted $\hat{T}$, which like any estimator is simply some quantity we compute from our data. 
\item Next, we do a sort of probabilistic thought experiment and ask: What is the chance that we would observe a value of $\hat{T}$ at least as large as the value we measured  IF our hypothesis was in-fact true.  The result is the \dfn{$p$-value}. 
\end{enumerate}

\begin{example}[hypothesis testing for a clinical trial]
Consider the example of a clinical trial. The effect of a drug, denoted $Y$ (e.g. blood pressure is measured in two groups) is measured in two groups.  One group is given a placebo, the other (the treatment group) is given a drug. Let $X=0$ for people in the control group and $X=2$ for those in the treatment group.   For simplicity we will assume that there are $N/2$ people in each group. We can model $Y$ with a regression model 
\begin{equation*}
Y|X \sim{\rm Normal}(\mu_C (1-X) + \mu_T X,\sigma^2)
\end{equation*}
{\bf We will assume $\sigma^2$ is know! This greatly simplifies the calculations!}
This is just a linear regression model since we could write
\begin{equation*}
\mu_C (1-X) + \mu_T X = \mu_C + (\mu_T-\mu_C)X = \beta_0 + \beta_1 X
\end{equation*}
where
\begin{align*}
\beta_0 &= \mu_C\\
\beta_1 &= \mu_T - \mu_C.
\end{align*}
We could estimate $\beta_0$ and $\beta_1$ as we always do in a linear regression model. We could also simply perform inference on the mean and of a Normal distribution within each group to obtain estimators of $\mu_C$ and $\mu_T$. For simplicity, let's pretend $\sigma$ is known for simplicity. This makes things simple, because then the sample distributions are 
 \begin{align*}
 \hat{\mu}_C &\sim {\rm Normal}\left(\hat{\mu}_C,\frac{\sigma^2}{N/2}\right)\\
  \hat{\mu}_T &\sim {\rm Normal}\left(\hat{\mu}_T,\frac{\sigma^2}{N/2}\right). 
 \end{align*}
 
Thus the (estimated) sample distribution of $\beta_1$ is 
\begin{equation*}
\hat{\beta}_1 \sim {\rm Normal}\left(\hat{\beta},\frac{4\sigma^2}{N}\right). 
\end{equation*}
In this case, our null hypothesis will be that $\beta_1  = 0$; that is, there is no effect of the drug. As our test statistic, we measure how far $\beta_1$ is from zero in standard deviations: 
\begin{equation*}
\hat{T} = \frac{\hat{\beta}_1}{{\rm se}(\hat{\beta}_1 )}
\end{equation*}
Remember that since we know $\sigma$,  ${\rm se}(\hat{\beta})$ is known and therefore, from the perspective of the sample distribution, this is just dividing by a constant. 
%Statistical significance can be understood in the language of $p$-values and hypothesis testing. The idea is that instead of looking directly at the sample distribution, we ask: How likely is it that we obtain a result at least as large as what we obtained if the null hypothesis were false. To this end, we consider the sample distribution conditioned on the null hypothesis being false:
Now, let $\hat{\beta}_1^*$ be the random variable representing the measured effect under the null hypothesis. Another way to say this is that $\hat{\beta}_1^*$ represents a measurement of $\beta_1$ from a replica generated under the assumption that $\beta_1=0$. Therefore, $\hat{\beta}_1^*$ will have a distribution centered at zero and with a standard deviation ${\rm se}(\hat{\beta}_1)$. This means the distribution of $\hat{\beta}_1^*$ is nothing but the sample distribution shifted to zero, or 
\begin{equation*}
\hat{\beta}_1^* \sim {\rm Normal}\left(0,\frac{4\sigma^2}{N}\right)
\end{equation*}
%This is a slightly different use of condition, since we are conditioning on a hypothesis, not an event in our sample. Think of it this way: the null hypothesis can itself be treated as a random variable which we are modeling 
 At this point we can answer the question posed in step 3: {\bf If the null hypothesis was true, how likely would we be to observe a value of $\hat{T}$ larger than the one we did?} This is determined by the $p$-value:
\begin{equation}\label{eq:pval}
p_v = P(|\hat{T}^*|>|\hat{T}||\hat{T})
\end{equation}
where $\hat{T}^*$ is the test statistic computed from $\hat{\beta}_1^*$ and the probability is taken over all the distribution of $\hat{T}^*$, while $\hat{T}$ is given by our data (hence why I use the conditioning notation). $p_v$, like $\hat{T}$, is a function of the data. See the python notebook were we compute $p_v$ with simulations. 

\end{example}

\item The above example is very simple because we assume that $\sigma$ is known and we have only a binary predictor. In reality, the computation of $p$-values is much more complex, however the principle and interpretation is the same!
\item {\bf Interpreting the $p$-value} If the $p$-value is very small, then it is highly unlikely we would have observed what we did when the null hypothesis was true. In this case, we can REJECT the null hypothesis as false. Usually some threshold is set for this, and if the $p_v$ is below that threshold we say our result in statistically significant. On the other hand, {\bf if $p_v$ is not small, it does not necessarily mean the null hypothesis is true.} A result is said to be statistically significant if $p_v<0.05$. Visually, we can see that $\beta_1$ is statistically significant exactly if $0$ is not contained in the confidence interval! 
\item {\bf Relationship between $p$-values and confidence intervals}.  The $p$-value is all about the ``tail'' of the sample distribution -- ``tail'' usually just means the ends of the distribution. Naturally there is connection between between $p$-values and confidence intervals, which also measure the width of the sample distribution. To illustrate the connection, we will again assume {\bf $\sigma$ is known}.  Since the  the sample distribution can be obtained by shifting the distribution of $\hat{\beta}_1^*$ to $\hat{\beta}_1$, the $p$-value, $p_v$, is exactly the chance of being outside the interval $[\hat{\beta}_1 - |\hat{\beta}_1|,\hat{\beta}_1 + |\hat{\beta}_1|]$. Therefore,  recalling the interpretation of confidence intervals, $\hat{\beta}_1$ will fall in the confidence interval with probability $p_v$ when the null hypothesis is true.  If $\sigma$ isn't known all this is only approximately true, but intuition is still. 



\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{./../figures/pvalueCI}
\caption{(left) The (two-sided) $p$-value and (right) the relationship between $p_v$ and the confidence interval. }\label{fig:pvalue}
\end{figure}


%\begin{example}[Generating data with different $p$-values. ]
%\end{example}
\end{itemize}





 \bibliographystyle{unsrt}
\bibliography{./../refs.bib}

\end{document}



\subsection{A simple example}
\begin{itemize}
\item Now let's consider the general regression model
\begin{equation}
Y = aX + b + \epsilon 
\end{equation}
where $X$ may be a continuous variable. 
{\bf How would we estimate $a$? }
\item Let's look at a simple example: 
Consider the example of a clinical trial conducted as follows. Suppose $N$ people participate in the trial, and are randomly assigned to the the control group (C) and treatment group (T) with probability $1/2$. People in T are given a drug whose effects is measure by a percent.  
\item We can model the distribution of blood pressure before and after treatment as 
\begin{equation}
Y_C \sim {\rm Normal}(\mu_C,\sigma)
\end{equation}
and 
\begin{equation}
Y_T \sim {\rm Normal}(\mu_T,\sigma).
\end{equation}
\item Our model for an individuals response can be framed as a regression model 
\begin{equation}\label{eq:clinical}
Y  = (\mu_T-\mu_C)X + \mu_C + \epsilon
\end{equation}
where $X=1$ if someone is in the treatment group and 
\begin{equation}
\epsilon \sim {\rm Normal}(0,\sigma_{\epsilon}). 
\end{equation}
\item How would we estimate $\mu_T$, $\mu_C$ and $\sigma$ from a sample? Assuming we know the group each patient has been assigned to, we observe that 
\begin{equation}
\E[Y|X=1] = \mu_T,\quad  \sqrt{{\rm var}(Y|X=1)} = \sigma_{\epsilon}. 
\end{equation}
This means we can estimate these from sample averages of $Y$ and $X$ (and similar for $X=0$).
%\begin{boxA}{$\sigma_{\epsilon}$ vs. $\sigma$}
% You might be tempted to say that the variance of $Y$ is also $\sigma_{\epsilon}$ -- but this is false! Why? (think back to the previous note when we looked at the marginal distribution of $Y$)
\item The sample distribution of the mean of the treatment group is
\begin{equation*}
\hat{\mu}_T \sim {\rm Normal}\left(\mu_T,\sigma/\sqrt{N}\right)
\end{equation*}
If  $\Delta \mu = \mu_T-\mu_C$, then as estimator $\Delta \mu$ is 
\begin{equation*}
\Delta \hat{\mu} =  \hat{\mu}_T-\hat{\mu}_C
\end{equation*}
which is really the slope of the regression line. 
The sample distribution of $\Delta \hat{\mu}$ is also Normal:
\begin{equation*}
\Delta \hat{\mu} \sim {\rm Normal}\left(\Delta \mu, \sqrt{2}\sigma/\sqrt{N}\right)
\end{equation*}





%\end{boxA}
\end{itemize}




\end{document}